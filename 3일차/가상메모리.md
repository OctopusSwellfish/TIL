# 가상메모리

### 가상 메모리가 출현한 이유

* 물리 메모리 크기의 한계를 극복하기 위해 나온 기술
* 물리 메모리보다 큰 프로세스를 수행하기 위해 나온 기술
  * 100mb메모리 크기에서 200mb 크기 프로세르를 수행할 수 있도록 하는 것

### 가상 메모리, 어떻게 가능한거지?

* **프로세스를 실행할 때, 필요한 부분만 메모리에 적재하기 때문에 가능**
  * 이런 부분은 페이지 단위일 수도 있고, 세그먼트 단위일 수도 있음(**현재에는 대부분 페이지 단위 사용**)

* 이처럼 현재 필요한 페이지만 메모리에 올리는 방법? **Demanding Paging(요구 페이징)**이라고 함
* 가상 메모리 만드는 방법은 대표적으로 두 가지가 있으나, **대부분 요구 페이징을 사용**
  * **가상 메모리와 요구 페이징을 같은 용어로 사용하는 경우가 많다**

### 요구 페이징

![img](https://user-images.githubusercontent.com/34755287/57119450-47043400-6da5-11e9-8810-c6a981a1d689.png)

* 두 프로세스 P1, P2는 필요한 페이지만 메모리에 할당함, **이 그림은 P1이 수행중일 때의 페이지 테이블**
* 기존의 페이지 테이블과 다른 점?
  * **valid bit**가 추가되었다.
    * 현재 메모리에 페이자가 있는지, 없는지 나타내는 비트
    * 현재 페이지가 메모리에 있다면 **1**, 없다면 **0**
* 만약에 CPU에서 지금 접근하려고 하는 페이지가 메모리에 없으면 어떡하지?
  * 만약에 위 사진에서 P1의 3번째 페이지에 접근해야 하는데, valid값이 0이면..?
    * **CPU인터럽트 신호를 발생하여, 운영체제 내부 ISR로 점프**
      * 디스크 내부의 프로세스 P1에 있는 2번째 페이지를 메모리에 할당하는 작업을 처리

![img](https://user-images.githubusercontent.com/34755287/57119451-47043400-6da5-11e9-9ca3-d0b250683bf0.png)

* 이 그림이 P1의 3번쨰 페이지를 메모리에 올린 후 모습

### Page Fault(페이지 부재)

* **CPU가 접근하려는 페이지가 메모리에 없는 경우, 즉, valid bit값이 0인 경우**

#### page fault 발생 시 처리하는 과정

![img](https://user-images.githubusercontent.com/34755287/57119452-479cca80-6da5-11e9-9c9e-50c3a3e74f53.png)

1. 해당 페이지가 메모리에 있는지 valid bit를 확인한다.
2. valid bit가 0이라면 CPU에 인터럽트 신호를 보내어 운영체제 내부 해당 ISR로 점프한다.
3. 해당 ISR에서 backing store(디스크)를 탐색하여 해당 프로세스의 페이지를 찾는다.
4. 해당 페이지를 비어있는 프레임에 할당한다.
5. 페이지 테이블을 갱신한다.(프레임 번호 설정, valid bit 1로 변경)
6. 다시 명령어로 돌아가서 실행한다.

### 요구 페이징 기법 2가지

* **Pure Demanding Paging**
  * **프로세스가 최초로 실행될 때는 어떤 페이지가 필요한 지 알 수 없으니까, 아무 페이지도 안 올리는 기법**
    * 프로그램 실행하자 마자 page fault가 발생
    * **장점:** 메모리를 최대한 효율적으로 사용할 수 있다.
    * **단점:** 시작부터 page fault가 발생하므로 속도면에서 느리다.

* **Prepaging**
  * 위와 반대되는 개념. **프로그램을 실행할 떄 필요할 것이라 판단되는 페이지를 미리 올리는 것**
    * **장점:** page fault가 발생할 확률이 적으므로 속도 면에서 빠르다.
    * **단점:** 미리 올라간 페이지를 사용하지 않는다면 메모리가 낭비된다.

### Swapping vs Demanding Paging

* 둘의 공통점 : 둘 다 메모리와 backing store 사이를 서로 오고 가는 기능을 수행
* 둘의 차이점 : Swapping은 **프로세스 단위로 이동**ㅣ, Demanding Paging은 **페이지 단위로 이동**

### Effective Access Time(유효 접근 시간)

* Demanding Paging은, 페이지 테이블에 해당 페이지가 없으면 backing store에서 메모리로 가져오는 과정이 있다.
  * **페이지 테이블에 해당 페이지가 있을 때와 없을 때 시간 차이가 발생한다!**
* 이런 시간 차이를 고려하여, 평균적으로 어느 정도 소요되는지 계산하는 것이 **유효 접근 시간**이라고 한다.
  * p: 페이지 부재 확률(page fault rate)
  * Tm: 메모리를 읽는 시간
  * Tp: Page fault가 발생했을 때 소요되는 시간(대부분 backing store(하드디스크)를 읽는 시간이 차지)
  * T = (1-p)Tm +pTp

* 예를 들면
  * Tm: 200nsec (DRAM)
  * Tp = 8msec (seek time + rotational delay + transfer time)
  * T = (1-p) 200 + p8,000,000 = 200 + 7,999,800*p
  * p = 1/1,000 => T = 8.2usec (40배 정도 느림)
  * p = 1/399,990 => T = 220nsec (10%정도 느림)
* page fault는 매우 적은 확률로 발생해야 효율적임을 알 수 있다!

### 그렇다면 페이지 부재는 어느 정도로 발생할까?(page fault 빈도)

* **지역성의 원리로 인해, 페이지 부재 확률은 매우 낮다**
* 지역성의 원리가 뭐지? :arrow_forward:**메모리 접근은 시간 적 지역성과 공간적 지역성을 가진다는 의미**
  * **시간적 지역성** : CPU는 어느 메모리 공간을 읽은 후, **시간이 지나도 그 공간을 다시 읽을 확률이 높다**
    * 예를 들어서 반복문은 하나의 코드 공간을 여러번 읽음
  * **공간적 지역성** : CPU가 메모리 공간을 읽을 때는, **인접한 범위 내에서 읽는다는 의미**
    * 프로그램은 대부분 절차적 순서로 구현되어 있기 때문에, 순서대로 읽는 경우가 빈번함
* 이와 같이 **페이지 부재가 현실적으로 발생할 확률은 매우 낮으므로 예제처럼 40배 느려지는 일은 거의 없을 것
  * 여기서 더 효율적으로 사용하기 위해서는. backing store로 HDD를 사용하기보다는 **SSD나 저가 DRAM과 같은 것을 사용하기**
